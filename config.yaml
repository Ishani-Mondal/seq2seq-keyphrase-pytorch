general:
  philly: False
  random_seed: 42
  test_200: False
  dataset: "kp20k"
  data_path: "data/kp20k/kp20k"
  vocab_path: "data/kp20k/kp20k.vocab.pt"

preproc:
  vocab_size: 50000
  max_unk_words: 1000
  words_min_frequency: 0
  max_src_seq_length: 300
  min_src_seq_length: 20
  max_trg_seq_length: 8
  min_trg_seq_length:  # None
  src_seq_length_trunc:  # None
  trg_seq_length_trunc:  # None
  shuffle: False
  lower: True
  keyphrase_ordering: "source"  # origin, source, alphabet, shuffle

training:
  epochs: 100
  batch_size: 16
  optimizer:
    step_rule: 'adam'  # adam
    learning_rate: 0.001
    clip_grad_norm: 5

evaluate:
  log_path: "logs"
  eval_method: "greedy"  # greedy, beam_search, beam_first
  max_sent_length: 20
  beam_size: 5
  batch_size: 16

checkpoint:
  checkpoint_path: "checkpoints"
  save_frequency: 1  # epoch
  experiment_tag: 'name_your_current_experiment_here'
  load_pretrained: False  # during test, enable this so that the agent load your pretrained model

model:
  embedding_size: 150
  rnn_hidden_size: 300
  pointer_softmax_hidden_dim: 64
  dropout: 0.3
  lambda_interp: 1.0
  lambda_fuse: 30.0
